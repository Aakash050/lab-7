---
title: "Lab 7: Functions + Fish"
author: "Aakash Kapadia"
format: 
  html:  
    embed-resources: true
    code-tools: true
    toc: true
    code-fold: true
editor: source
execute:
  warning: false
  message: false
  echo: True
---

The goal of this lab is learn more about exploring missing data and writing
modular code.

```{r}
#| label: setup
library(tidyverse)
library(here)
BlackfootFish <-read_csv(here("data", "BlackfootFish.csv"))

```

## The Data

This lab's data concerns mark-recapture data on four species of trout from the
Blackfoot River outside of Helena, Montana. These four species are
**rainbow trout (RBT)**, **westslope cutthroat trout (WCT)**, **bull trout**,
and **brown trout**.

Mark-recapture is a common method used by ecologists to estimate a population's
size when it is impossible to conduct a census (count every animal). This method
works by *tagging* animals with a tracking device so that scientists can track
their movement and presence.

## Data Exploration

The measurements of each captured fish were taken by a biologist on a raft in
the river. The lack of a laboratory setting opens the door to the possibility of
measurement errors.

**1. Let's look for missing values in the dataset. Output ONE table that answers BOTH of the following questions:**

+ **How many observations have missing values?**
+ **What variable(s) have missing values present?**

**1796 observations have missing values, and they're all found in weight.This can also be seen through looking directly at the table, where weight is not a part of the dataset, even though it's written there.**

::: callout-tip
# You should use `across()`!
:::

```{r}
#| label: find-missing-values
# Found sum(is.na) through the textbook, where this counts how many times NA values appear in rows. The missing count >0 filters the table to only include places where there is at least 1 NA.
missing_table <- BlackfootFish |> 
  summarise(across(everything(), 
                   ~ sum(is.na(.)))) |> 
  pivot_longer(everything(), names_to = "Variable", 
               values_to = "Missing_Count") |> 
  filter(Missing_Count > 0)

print(missing_table)
  
```

**2. Create ONE thoughtful visualization that explores the frequency of missing values across the different years, sections, and trips.**

**Revisions: I changed my graph of missing values compared to years, sections, and trips to a heat map (getting inspiration from Parker Mascott in the discord channel). There are a few reasons I did this. When researching heat maps, I realized that heatmaps make it really easy to identify patterns in large datasets (due to color gradients), and with 1796 observations, a heatmap would be more appropriate. Additionally, heatmaps allow for quick comparisons across different groups, allowing me to effectively plot years, sections, trips, and missing values.**

**Changes I made: First, I changed my filter to a mutate on my is.na code, so that I could include missing values as a fill on my graph. Previously, I had only included na values on my graph, which allowed me to plot them, but didn't show the reader the difference between missing values and non missing values, only showing them missing values (frequency was missing). *Also included a group by to accomplish the mutate (as mutate works row by row). Then, to get the percent of missing values, I added up the total number of observations, using n(), and created a percent missing variable that used my missing and total number of values. Finally, I included this on my aes(mapping). To do so, I changed my line color = section to fill = percent_misssing_values, and included geom_tile(), which is the code for a heatmap. I also faceted by trip (first I tried faceting by section but realized I needed trip to split into 1 and 2, instead of r considering trip as a numeric variable and therefore giving me a scale from 0 - 2 by 0.5), to include this as well, and added a color scale to indicate to readers where missing values were more prevalent. I also added theme_minimal to clean up the graph, removing the gray space, and grid lines. Finally, I added labels, which I should've done earlier, to make the plot easier for the reader to understand.**
```{r}
#| label: visual-of-missing-values-over-time
BlackfootFish |>
  group_by(year, section, trip) |>
  mutate(missing_values = sum(if_any(everything(),
                                     is.na)),
         total=n(),
         percent_missing_values = (missing_values/total)*100) |>
ggplot(BlackfootFish,
       mapping=aes(x=year, 
                   y=section,
                   fill=percent_missing_values)) +
  geom_tile() +
  facet_wrap(~ trip) +
  #Found this in the r help section, fill refers to the percent of missing values. 
  scale_fill_gradient(low = "Midnight Blue", 
                      high = "Sky Blue",
                      name = "Percent Missing (0 - 100)") +
  labs(x = "Year",
       y = "Section",
       subtitle = "Trip",
       title = "Heatmap of missing values vs years, sections, and trips") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 90, 
                                    hjust = 0.5),
        axis.title.x = element_text(hjust = 0.5) )
```

## Rescaling the Data

If I wanted to rescale every quantitative variable in my dataset so that they
only have values between 0 and 1, I could use this formula:

</br>

$$y_{scaled} = \frac{y_i - min\{y_1, y_2,..., y_n\}}{max\{y_1, y_2,..., y_n\} 
- min\{y_1, y_2,..., y_n\}}$$

</br>

I might write the following `R` code to carry out the rescaling procedure for the `length` and `weight` columns of the `BlackfoorFish` data:

```{r}
#| echo: true
#| eval: false

BlackfootFish <- BlackfootFish |> 
  mutate(length = (length - min(length, na.rm = TRUE)) / 
           (max(length, na.rm = TRUE) - min(length, na.rm = TRUE)), 
         weight = (weight - min(weight, na.rm = TRUE)) / 
           (max(weight, na.rm = TRUE) - min(length, na.rm = TRUE)))
```

This process of duplicating an action multiple times can make it difficult to
understand the intent of the process. *Additionally, it can make it very difficult to spot mistakes.*

**3. What is the mistake I made in the above rescaling code?**
In the code above, you rescaled weight using length in the line min(length, na.rm = TRUE))). Here, you are rescaling weight according to minimum length, which doesn't necessarily correspond to minimum weight,  

When you find yourself copy-pasting lines of code, it's time to write a
function, instead!

**4. Transform the repeated process above into a `rescale_01()` function. Your function should...**

+ **... take a single vector as input.**
+ **... return the rescaled vector.**

```{r}
#| label: write-rescale-function
#Found information on the range function in the r help page
rescale_01 <- function(x) {
  stopifnot(is.numeric(x), length(x)>1)
  range_vals <- range(x, na.rm=TRUE)
  return((x - range_vals[1]) / (range_vals[2] - range_vals[1]))
}
```

::: callout-tip
# Efficiency 

Think about the efficiency of the function you wrote. Are you calling the
**same** function multiple times? You might want to look into the `range()` 
function. 
:::

**5. Let's incorporate some input validation into your function. Modify your previous code so that the function stops if ...**

+ **... the input vector is not numeric.**
+ **... the length of the input vector is not greater than 1.**

::: callout-tip
# Modify Previous Code

Do not create a new code chunk here -- simply add these stops to your function
above!
:::

## Test Your Function

**6. Run the code below to test your function. Verify that the maximum of your rescaled vector is 1 and the minimum is 0!**

```{r}
#| label: verify-rescale-function

x <- c(1:25, NA)

rescaled <- rescale_01(x)
min(rescaled, na.rm = TRUE)
max(rescaled, na.rm = TRUE)
```

Next, let's test the function on the `length` column of the `BlackfootFish` data.

**7. The code below makes a histogram of the original values of `length`. Add a plot of the rescaled values of `length`. Output your plots side-by-side, so the reader can confirm the only aspect that has changed is the scale.**

::: callout-warning
This will require you to call your `rescale_01()` function within a `mutate()`
statement in order to create a `length_scaled` variable.
:::
**Revisions: When looking back at the graphs, they had different scales but the graphs also looked different. This is because I didn't specify a bindwith in my scaled graph, meaning overall, I had a graph with the same data, but it looked different. By controlling how large my bins were (45/1000 = 0.045), the graphs now look the same. When creating graphs in the future, I can use bindwith for scaled graphs, diving by the scale to get what my new bindwith should be.**
```{r}
#| label: compare-original-with-rescaled-lengths
#| layout-ncol: 2
  ggplot(BlackfootFish, aes(x = length)) + 
  geom_histogram(binwidth = 45) + 
  labs(x = "Original Values of Fish Length (mm)") + 
  scale_y_continuous(limits = c(0, 4000))

fish2 <- BlackfootFish |> 
  mutate(length_scaled = rescale_01(length)) 

ggplot(fish2, aes(x = length_scaled)) + 
  geom_histogram(binwidth = 0.045) + 
  labs(x = "Scaled Values of Fish Length (mm)") + 
  scale_y_continuous(limits = c(0, 4000))
```

::: callout-tip
1. Set the y-axis limits for both plots to go from 0 to 4000 to allow for direct comparison across plots.

2. Pay attention to `binwidth`!

3. Use a Quarto code chunk option to put the plots side-by-side.
:::

## Use Variables within a Dataset

Suppose you would like for your `rescale()` function to perform operations on a **variable within a dataset**. Ideally, your function would take in a data
frame and a variable name as inputs and return a data frame where the variable
has been rescaled.

**8. Create a `rescale_column()` function that accepts two arguments:**

+ **a dataframe**
+ **the name(s) of the variable(s) to be rescaled**

**The body of the function should call the original `rescale_01()` function you wrote previously. Your solution MUST use one of the `rlang` options from class.**

::: callout-tip
If you are struggling with this task, I recommend looking back over the 
[data frame functions](https://r4ds.hadley.nz/functions.html#data-frame-functions)
section of R for Data Science!
:::
**Revisions: After looking over your feedback, I implemented function stops to check for inputs being a dataframe, and our columns being in our dataframe. I did this through the slides, where I found the setup for these arguments. I specifically didn't use the stopifnot as I wanted to include a message in case these weren't correct, but kept the stopisnot for our numerical checks as it allowed me to check both at once. The other change I made is to use the most modern version of across. I found the syntax for this in the textbook, where specifying the .names argument allows me to specify that I want the original measurements, and the scaled measurements. Whenever I want to compare data to a altered form of the same data, I plan to use this.**
```{r}
#| label: rescale-data-frame-function
rescale_01 <- function(x) {
  stopifnot(is.numeric(x), length(x)>1)
  range_vals <- range(x, na.rm=TRUE)
  return((x - range_vals[1]) / (range_vals[2] - range_vals[1]))
}
rescale_column <-function(df, group_vars) {
if(!is.data.frame(df)){
    stop("Please provide a data frame input for the df argument")
}  
if(!all(group_vars %in% colnames(df))){
    stop("The columns selected must be in our data frame")
} 
  df |>
  mutate(across({{group_vars}}, rescale_01, .names = "{.col}_scaled"))
}
```

**9. Use your `rescale_column()` function to rescale *both* the `length` and `weight` columns.**

::: callout-warning
I expect that you carry out this process by calling the `rescale_column()` function only ONE time!
:::

```{r}
#| label: rescale-two-columns
rescale_column(BlackfootFish, c("length","weight"))
```
